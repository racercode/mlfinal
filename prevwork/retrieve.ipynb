{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 12:55:21.467309: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-30 12:55:21.476497: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-30 12:55:21.575180: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-30 12:55:21.575291: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-30 12:55:21.587711: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-30 12:55:21.633688: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-30 12:55:21.635056: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-30 12:55:22.542691: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as sk_metrics\n",
    "import tempfile\n",
    "import os\n",
    "pd.options.display.max_rows = 100\n",
    "# Preset matplotlib figure sizes.\n",
    "matplotlib.rcParams['figure.figsize'] = [9, 6]\n",
    "\n",
    "print(tf.__version__)\n",
    "# To make the results reproducible, set the random seed value.\n",
    "random_seed = 22\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = 'test_data_ver1.csv'\n",
    "train_and_validation_data_path = 'train_data_ver3.csv'\n",
    "\n",
    "dataset = pd.read_csv(train_and_validation_data_path)\n",
    "dataset = dataset.drop(['id','home_team_abbr','away_team_abbr','is_night_game','home_pitcher','away_pitcher','home_team_rest','away_team_rest','home_pitcher_rest','away_pitcher_rest','season', 'home_batting_leverage_index_avg_skew', 'away_batting_leverage_index_avg_skew', 'home_pitcher_SO_batters_faced_skew', 'away_pitcher_SO_batters_faced_skew'], axis=1)\n",
    "#dataset = dataset[['home_team_win', 'home_batting_onbase_plus_slugging_10RA', 'away_batting_onbase_plus_slugging_10RA', 'home_team_wins_mean', 'away_team_wins_mean', 'away_pitching_SO_batters_faced_10RA', 'away_pitching_SO_batters_faced_10RA', 'home_batting_onbase_plus_slugging_mean', 'away_batting_onbase_plus_slugging_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance Ranking (Most to Least Important):\n",
      "                                    Feature  Ranking\n",
      "43                      away_team_wins_skew        1\n",
      "15      away_pitching_SO_batters_faced_10RA        2\n",
      "50   home_batting_onbase_plus_slugging_mean        3\n",
      "44            home_batting_batting_avg_mean        4\n",
      "128               home_pitcher_wpa_def_mean        5\n",
      "..                                      ...      ...\n",
      "65             away_batting_onbase_perc_std      144\n",
      "51    home_batting_onbase_plus_slugging_std      145\n",
      "83      home_pitching_SO_batters_faced_skew      146\n",
      "39                       home_team_wins_std      147\n",
      "104      away_pitching_H_batters_faced_skew      148\n",
      "\n",
      "[148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Set up RFE to select the top 2 features\n",
    "rfe = RFE(estimator=model, n_features_to_select=10)\n",
    "X_train = dataset.drop('home_team_win', axis=1)\n",
    "Y_train = dataset['home_team_win']\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Initialize RFE with Logistic Regression model and choose number of features to select\n",
    "rfe = RFE(estimator=model, n_features_to_select=1)\n",
    "\n",
    "# Fit RFE on the training data\n",
    "rfe.fit(X_train, Y_train)\n",
    "\n",
    "# Get the ranking of features (1 = most important, higher = less important)\n",
    "feature_ranking = rfe.ranking_\n",
    "\n",
    "# Create a DataFrame to show features with their rankings\n",
    "feature_names = X_train.columns\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Ranking': feature_ranking\n",
    "})\n",
    "\n",
    "# Sort the features by importance (lowest rank = most important)\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Ranking')\n",
    "\n",
    "# Print the features from most important to least important\n",
    "print(\"Feature Importance Ranking (Most to Least Important):\")\n",
    "print(feature_importance_df)\n",
    "# Check feature rankings (1 = most important, higher = less important)\n",
    "#print(\"Feature Rankings:\", rfe.ranking_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.dense = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(num_chunks: int):\n",
    "    chunk_size = len(dataset) // num_chunks\n",
    "    chunks = [dataset.iloc[i * chunk_size:(i + 1) * chunk_size] for i in range(num_chunks)]\n",
    "    # Handle any remaining rows (if the dataset isn't perfectly divisible)\n",
    "    if len(dataset) % num_chunks != 0:\n",
    "        chunks[-1] = pd.concat([chunks[-1], dataset.iloc[num_chunks * chunk_size:]])\n",
    "\n",
    "    best_accuracy, best_loss, best_model = -1, -1, -1\n",
    "\n",
    "    for v in range(num_chunks):\n",
    "        validation_dataset = chunks[v]\n",
    "        train_dataset = dataset.drop(chunks[v].index)\n",
    "\n",
    "        # Split the features and the target values\n",
    "        x_train = train_dataset.drop('home_team_win', axis=1)\n",
    "        y_train = train_dataset['home_team_win']\n",
    "        x_validation = validation_dataset.drop('home_team_win', axis=1)\n",
    "        y_validation = validation_dataset['home_team_win']\n",
    "\n",
    "        # Convert the features and the target values to TensorFlow tensors\n",
    "        x_train = tf.constant(x_train, dtype=tf.float64)\n",
    "        y_train = tf.constant(y_train, dtype=tf.float64)\n",
    "        x_validation = tf.constant(x_validation, dtype=tf.float64)\n",
    "        y_validation = tf.constant(y_validation, dtype=tf.float64)\n",
    "\n",
    "        # Instantiate the model\n",
    "        model = LogisticRegressionModel()\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "        model.fit(x_train, y_train, epochs=5, batch_size=1)\n",
    "        loss, accuracy = model.evaluate(x_validation, y_validation)\n",
    "        print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
    "\n",
    "        if best_accuracy == -1 or accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_loss = loss\n",
    "            best_model = model\n",
    "\n",
    "    return best_accuracy, best_loss, best_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8854/8854 [==============================] - 8s 839us/step - loss: 0.6941 - accuracy: 0.5352\n",
      "Epoch 2/5\n",
      "8854/8854 [==============================] - 8s 863us/step - loss: 0.6907 - accuracy: 0.5443\n",
      "Epoch 3/5\n",
      "8854/8854 [==============================] - 7s 799us/step - loss: 0.6911 - accuracy: 0.5498\n",
      "Epoch 4/5\n",
      "8854/8854 [==============================] - 7s 822us/step - loss: 0.6911 - accuracy: 0.5504\n",
      "Epoch 5/5\n",
      "8854/8854 [==============================] - 8s 885us/step - loss: 0.6911 - accuracy: 0.5455\n",
      "70/70 [==============================] - 0s 998us/step - loss: 0.6891 - accuracy: 0.5540\n",
      "Loss: 0.6890743970870972, Accuracy: 0.553999125957489\n",
      "Epoch 1/5\n",
      "8854/8854 [==============================] - 8s 842us/step - loss: 0.6947 - accuracy: 0.5390\n",
      "Epoch 2/5\n",
      "8854/8854 [==============================] - 7s 843us/step - loss: 0.6909 - accuracy: 0.5400\n",
      "Epoch 3/5\n",
      "8373/8854 [===========================>..] - ETA: 0s - loss: 0.6918 - accuracy: 0.5388"
     ]
    }
   ],
   "source": [
    "best_accuracy, best_loss, best_model = cross_validation(5)\n",
    "print(f\"Best accuracy: {best_accuracy}, Best loss: {best_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
